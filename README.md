# ApprehendIris

## 什么是ApprehendIris

Apprehend：词汇意义上，"Apprehend" 表示理解、领悟、理解等。在这个应用的上下文中，"Apprehend" 表示该应用有能力理解和处理输入的文本数据。

Iris："Iris" 是一种花朵的名称，也是眼睛的虹膜的名称。在这个名字中，"Iris" 象征着应用的观察、分析和洞察文本的能力。

Apprehend Iris是一个结合自然语言处理（NLP）和大型语言模型（LLM）的应用程序，旨在提供一种抽象且可扩展的方法来处理文本分析任务。该应用的目标是帮助用户更有效地处理和理解文本数据。

Apprehend Iris利用NLP中的多种技术和方法，包括文本分类、情感分析、命名实体识别等，结合强大的大语言模型的能力，以实现更高级的文本处理任务。该应用的核心功能是提供一种用户友好的界面和接口，使用户能够轻松地在多个领域和场景下使用自然语言处理技术。

与传统的NLP方法相比，Apprehend Iris的特色在于它的抽象性和可扩展性。通过使用大型语言模型，该应用可以从大量的文本数据中学习，并且能够推理和理解更广泛的语义信息。这种抽象和可扩展性使得Apprehend Iris可以应对各种文本分析任务，并且在不同领域和应用场景中具有广泛的适用性。

通过Apprehend Iris，用户可以利用强大的NLP技术来执行诸如文本分类、情感分析、信息提取等任务。无论是在企业中用于文本挖掘和情报分析，还是在学术研究中用于文本理解和信息抽取，Apprehend Iris都可以提供灵活且高效的解决方案。

总之，Apprehend Iris是一个结合了NLP和大型语言模型的应用程序，旨在提供一个抽象且可扩展的文本分析解决方案。它的特色在于利用大型语言模型的能力，提供广泛的文本处理功能，并适用于各种领域和应用场景。无论是在企业还是学术领域，使用Apprehend Iris可以帮助用户更好地理解和利用文本数据。


## 为什么要使用ApprehendIris

目前的LLM问答存在以下问题：

上下文长度限制：大语言模型在生成回复时，通常需要依赖前面的上下文内容来理解用户的意图和语境。然而，由于计算资源和效率的限制，模型对上下文的长度通常有一定的限制。这可能导致在处理较长对话时，模型无法充分理解完整的上下文信息，从而影响回复的准确性和连贯性。

意识性错觉：大语言模型虽然可以生成具有连贯性和合理性的文本，但其并没有真正的意识和理解能力。模型生成的回复是基于在海量训练数据中学习到的模式和统计规律，而非真正理解语义和主题。这可能导致模型在某些情况下表现出“懂了一点但不明白全部”的现象，给人一种模型具有意识性的错觉。

模型知识过时：大语言模型的训练数据通常是在特定时间段内搜集的，而模型的知识截止时间是有限的。随着时间的推移，新的信息、发现和事件会发生，但模型无法及时获取和学习最新的知识。因此，在回答关于最新事件、研究或新兴领域的问题时，模型可能提供过时或不准确的答案。

无法应对专业领域问题：大语言模型的训练数据通常是从互联网上收集而来，涵盖了各个领域，但并不深入。当涉及到某些专业领域或具体领域知识时，模型可能无法提供准确的答案。模型在特定领域中的知识和理解能力有限，因此在专业问题上的回答可能不如领域专家准确和全面。

应用与大模型强耦合：目前大语言模型的应用通常需要依赖云端服务器和强大的计算资源。对于某些需要保护用户隐私或需要离线执行的应用场景，将大语言模型应用于本地计算设备可能存在挑战。此外，大语言模型的复杂性和资源需求也意味着开发和部署这些应用需要额外的投入和成本。

项目的价值体现在：

突破大模型的限制：大模型应用过程中，限制比较多（上文描述），需要突破这些限制以更充分发挥大模型的作用。

降低大模型使用专业数据的成本：训练一个大型语言模型需要大量的计算资源和数据。对于一般人来说，构建和训练一个大模型的成本是非常高昂的。

辅助人类思维：大模型可以作为辅助工具来帮助人们解决问题和扩展思维能力。通过与大模型的交互，人们可以从中获得启发、建议和不同的视角。大模型可以提供资源丰富的信息和知识，并与用户进行对话，促进思维的发展和创新。

对大模型抽象：随着大模型的发展和普及，有可能将人类自身视为一种"大模型"。通过对大模型的研究和理解，可以更好地了解并推进人类思维和智能的发展。将人类思维与大模型进行类比和相互交叉，有助于我们更好地理解人类认知的本质。

开发基于大模型的应用可以为用户提供更广泛和复杂的语言处理能力，同时也为开发者提供了一个更高层次的抽象和应用开发的基础。这样的应用有助于改善人机交互、智能助理、语言翻译、信息检索等领域的用户体验和效果。同时，该应用也需要综合考虑大模型的局限性和应用场景的特点，以确保输出的结果准确、可靠且符合用户的需求。

## ApprehendIris面向用户

ApprehendIris 主要面向的用户是需要使用大模型从大量文本中提取信息的用户。

## 实现思路以及使用方法

### 实现思路

Apprehend Iris项目整体分为两部分：传统自然语言处理部分和LLM（Large Language Model）部分。这两部分共同协作完成具体任务的解决方案。
方案执行过程如下：

1.给定一个具体的上下文（长）：首先，需要提供一个包含相关信息的上下文文本。这可以是一篇文章、一个段落、一个问题集，或者是其他包含所需信息的任何文本形式。
2.给定一个具体的问题（短）：其次，指定一个短小的问题，需要从给定的上下文中获取答案。这个问题可以是关于上下文中的某个特定细节、一个推理问题或任何需要解决的具体查询。
3.LLM指导传统自然语言处理进行预处理：在这一步中，使用传统的NLP处理方法对资料与问题进行分句、分词、向量化，然后计算每个片段间的相似度，提取出回答问题需要的核心信息。
4.LLM使用核心信息与问题求解出答案：基于第3步中提取的核心信息，LLM利用其强大的语言理解能力和模式识别能力，结合给定的问题，通过推理和问答技术来解决问题。LLM在整个过程中可以结合上下文的信息进行具体推理，并生成或选择最合适的答案作为最终的解决方案。

Apprehend Iris的软件架构设计可以分为三个层次：顶层核心、中间适配层和底层实体资源。下面将详细说明每个层次的功能和交互关系：

1. 顶层核心：
(1) 核心功能：顶层核心是整个架构的核心部分，它的主要任务是整合LLM、数据和NLP算法，以提供标准格式的输出。核心利用LLM的强大语言理解能力和模式识别能力来处理自然语言任务，并将数据和算法整合在一起，以生成高质量的标准输出。它还提供了标准端口与中间适配层进行交互。
(2) 核心接口：顶层核心提供标准的接口和协议，使得中间适配层可以与核心进行通信，传递数据和请求处理。
2. 中间适配层：
(1) 数据源封装：适配层封装了各种数据源，如数据库、文件系统、网络等，以便从这些数据源中提取数据，并将其转换为标准格式供核心使用。
(2) 模型封装：适配层封装了各种模型的接口，其中传统的NLP模型与大语言模型被抽象为统一接口。
(3) 输出封装：模型输出接口的封装，提供统一的标准输出。
3. 底层实体资源：
(1) 实体资源功能：底层实体资源由核心通过适配层调度和管理。它包括各种数据源、NLP算法、LLM等资源。这些资源可以是内部开发的、第三方的或者云端的，提供了不同的功能和处理能力。
4. 用户开放视图：底层实体资源向用户开放多模态的输出视图，以便用户可以使用不同的方式（如文本、语音、图形等）获取处理结果。

Apprehend Iris的软件架构设计采用了层次化架构，顶层核心整合了LLM、数据和NLP算法，并提供标准格式输出。中间适配层起到转换的作用，封装了各种数据源、NLP算法和LLM接口，并提供标准的数据接口给核心使用。底层实体资源由核心通过适配层调度，包括各种资源，并向用户开放多模态输出视图。这样的架构设计使得系统具有灵活性、可扩展性和可维护性，能够有效处理复杂的自然语言处理任务。

### 使用方法

针对想直接使用产品的用户，运行`main.py`文件即可。（需要安装Python 3以及需要的依赖包）

针对开发者，参照 UI/App.py 中的代码即可。
